{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7c8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed5181-bb95-4581-97a5-090aabc0f14a",
   "metadata": {},
   "source": [
    "# TESTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0eb51dd-3d0a-4ed2-8270-e67825dad235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "63/63 [==============================] - 0s 4ms/step\n",
      "[0.00247557 0.00799345 0.92676744 ... 0.98028461 0.94102751 0.96274065]\n",
      "CNN-SVM Accuracy: 0.8806193806193806\n",
      "CNN-SVM Precision: 0.8434579439252337\n",
      "CNN-SVM Recall: 0.6772983114446529\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = 'datasets/proper_Test_Data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Extract features and target\n",
    "X_test = data['statement']\n",
    "y_test = data['toxic_label']\n",
    "\n",
    "max_words = 2000  # Number of unique words to consider\n",
    "max_sequence_length = 200  # Maximum length of a sequence\n",
    "\n",
    "tokenizer = joblib.load('output_model/tokenizer_proper.pkl')\n",
    "\n",
    "# Tokenize and pad sequences using the same tokenizer used during training\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Load the CNN model\n",
    "loaded_cnn_model = load_model('output_model/cnn_model_proper.h5')\n",
    "\n",
    "# Extract features from the loaded CNN model\n",
    "cnn_features_model = Sequential(loaded_cnn_model.layers[:-1])\n",
    "X_test_cnn_features = cnn_features_model.predict(X_test_padded)\n",
    "\n",
    "# Load the SVM model\n",
    "loaded_svm_model = joblib.load('output_model/svm_model_proper.pkl')\n",
    "\n",
    "# Predict using the SVM model\n",
    "y_pred = loaded_svm_model.predict(X_test_cnn_features)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "threshhold = 0.5\n",
    "y_pred = (y_pred > threshhold).astype(int)\n",
    "\n",
    "# Calculate metrics for SVM\n",
    "svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_precision = precision_score(y_test, y_pred)\n",
    "svm_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Display SVM metrics\n",
    "print(\"CNN-SVM Accuracy:\", svm_accuracy)\n",
    "print(\"CNN-SVM Precision:\", svm_precision)\n",
    "print(\"CNN-SVM Recall:\", svm_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4157f9a5-ec6e-481c-a539-435a12c44885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:6 out of the last 68 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028E89E31310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[0.95272429 0.96281128 0.06356143 1.08058877 0.99358041 0.90716719\n",
      " 0.91861605]\n"
     ]
    }
   ],
   "source": [
    "# Load relevant models\n",
    "loaded_cnn_model = load_model('output_model/cnn_model_proper.h5')\n",
    "loaded_svm_model = joblib.load('output_model/svm_model_proper.pkl')\n",
    "tokenizer = joblib.load('output_model/tokenizer_proper.pkl')\n",
    "max_sequence_length = 200  # Maximum length of a sequence\n",
    "\n",
    "\n",
    "# Extract features and target\n",
    "X_test = ['NiGGer','STuPID','die','you are pussy','BOBO','putang','ez']\n",
    "\n",
    "# Tokenize and pad sequences using the same tokenizer used during training\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Extract features from the loaded CNN model\n",
    "cnn_features_model = Sequential(loaded_cnn_model.layers[:-1])\n",
    "X_test_cnn_features = cnn_features_model.predict(X_test_padded)\n",
    "\n",
    "# Predict using the SVM model\n",
    "y_pred = loaded_svm_model.predict(X_test_cnn_features)\n",
    "\n",
    "# threshhold = 0.5\n",
    "# y_pred = (y_pred > threshhold).astype(int)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4d742-b244-4370-8b5b-6ca3ddce6a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
